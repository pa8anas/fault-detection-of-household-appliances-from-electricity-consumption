{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc, mean_squared_error, hinge_loss\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "7xpkFUYqNPje"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/DRED.csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "path = \"./content/drive/MyDrive/DRED.csv\"\n",
        "\n",
        "def classifer_metrics(y_true, y_pred):\n",
        "    classifer_accuracy = accuracy_score(y_true, y_pred)*100\n",
        "    classifier_f1_score = f1_score(y_true, y_pred, average='macro')*100\n",
        "    return classifer_accuracy, classifier_f1_score\n",
        "\n",
        "def classifer_metrics(y_true, y_pred):\n",
        "    classifer_accuracy = accuracy_score(y_true, y_pred)*100\n",
        "    classifier_f1_score = f1_score(y_true, y_pred, average='macro')*100\n",
        "    return classifer_accuracy, classifier_f1_score\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    plots the roc curve based of the probabilities\n",
        "    \"\"\"\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "\n",
        "\n",
        "# This line reads the dataset names instead of hardcoding them.\n",
        "datasets = os.listdir('/content/drive/MyDrive/datasets')\n",
        "#dataset = pd.read_csv(path)\n",
        "iterations = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flk_gPFfNbVM",
        "outputId": "67318933-ae2e-4c94-d034-91ebfe283bee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DNN\n",
        "training_time_SVM = {k:[] for k in datasets}\n",
        "training_accuracy_SVM = {k:[] for k in datasets}\n",
        "training_f1_score_SVM = {k:[] for k in datasets}\n",
        "testing_time_SVM = {k:[] for k in datasets}\n",
        "testing_accuracy_SVM = {k:[] for k in datasets}\n",
        "testing_f1_score_SVM = {k:[] for k in datasets}\n",
        "\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(f\"------------- {dataset[:-4]} Execution -------------\")\n",
        "    with open(f'/content/drive/MyDrive/datasets/{dataset}','r') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file)\n",
        "        data = list(csv_reader)\n",
        "\n",
        "    data = np.array(data)\n",
        "    data = data.astype(np.float)\n",
        "        \n",
        "    num_observations = data.shape[0]\n",
        "    num_features = data.shape[1] - 1\n",
        "\n",
        "    print(f\"Dataset Size: {data.shape}\\n\")\n",
        "\n",
        "    for i in range(iterations):\n",
        "         # Shuffle the data\n",
        "        shuffle_idx = np.random.permutation(num_observations)\n",
        "        shuffled_data = data[shuffle_idx,:]\n",
        "\n",
        "        X = shuffled_data[:,:-1]\n",
        "        Y = shuffled_data[:,-1]\n",
        "\n",
        "             \n",
        "        le = LabelEncoder()\n",
        "        Y = le.fit_transform(Y)\n",
        "\n",
        "        # Split the data for training and testing\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state = 0)\n",
        "        \"\"\"\n",
        "        def recall(y_true, y_pred):\n",
        "            true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "            possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "            recall = true_positives / (possible_positives + K.epsilon())\n",
        "            return recall\n",
        "\n",
        "        def precision(y_true, y_pred):\n",
        "            true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "            predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "            precision = true_positives / (predicted_positives + K.epsilon())\n",
        "            return precision\n",
        "\n",
        "\n",
        "        def f1_score(y_true, y_pred):\n",
        "            precision_m = precision(y_true, y_pred)\n",
        "            recall_m = recall(y_true, y_pred)\n",
        "            return 2*((precision_m*recall_m)/(precision_m+recall_m+K.epsilon()))\"\"\"\n",
        "            \n",
        "\n",
        "       \n",
        "        classifier = SVC(kernel = 'poly', random_state = 0)\n",
        "\n",
        "        training_time_start = time.time()\n",
        "        \n",
        "        classifier.fit(X_train, y_train)\n",
        "        y_train_pred = classifier.predict(X_train)\n",
        "        classifir_accuracy, classifier_f1_score = classifer_metrics(y_train, y_train_pred)\n",
        "        training_accuracy_SVM[dataset].append(classifir_accuracy)\n",
        "        training_f1_score_SVM[dataset].append(classifier_f1_score)\n",
        "\n",
        "        training_time_end = time.time()\n",
        "        training_time_SVM[dataset].append(training_time_end - training_time_start)\n",
        "\n",
        "        testing_time_start = time.time()\n",
        "        \n",
        "        y_test_pred = classifier.predict(X_test)\n",
        "        classifir_accuracy, classifier_f1_score = classifer_metrics(y_test, y_test_pred)\n",
        "        testing_accuracy_SVM[dataset].append(classifir_accuracy)\n",
        "        testing_f1_score_SVM[dataset].append(classifier_f1_score)\n",
        "        \n",
        "        testing_time_end = time.time()\n",
        "        testing_time_SVM[dataset].append(testing_time_end - testing_time_start)    \n",
        "        \n",
        "        \n",
        "        y_test_pred = classifier.predict(X_test)\n",
        "        \n",
        "\n",
        "        print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "        print(\"mse:\", mean_squared_error(y_test, y_test_pred))\n",
        "        #print(\"loss:\", hinge_loss(y_test, y_test_pred))\n",
        "\n",
        "        classifier_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        \n",
        "\n",
        "         \n",
        "        print(f\"Training Time_{i+1}: --- {training_time_SVM[dataset][i]:.4f} seconds ---\")\n",
        "        print(f\"Training Accuracy_{i+1}: --- {training_accuracy_SVM[dataset][i]:.2f}%\")\n",
        "        print(f\"Training F1 Score_{i+1}: --- {training_f1_score_SVM[dataset][i]:.2f}%\")\n",
        "        print(f\"Testing Time_{i+1}: --- {testing_time_SVM[dataset][i]:.4f} seconds ---\")\n",
        "        print(f\"Testing Accuracy_{i+1}: --- {testing_accuracy_SVM[dataset][i]:.2f}%\")\n",
        "        print(f\"Testing F1 Score_{i+1}: --- {testing_f1_score_SVM[dataset][i]:.2f}%\")\n",
        "        print(\"----------------------------------------------\\n\")\n",
        "\n",
        "    print(f\"\\nAverage Training Time: --- {np.mean(training_time_SVM[dataset]):.4f} seconds ---\")\n",
        "    print(f\"Average Training Accuracy: --- {np.mean(training_accuracy_SVM[dataset]):.2f}%\")\n",
        "    print(f\"Average Training F1 Score: --- {np.mean(training_f1_score_SVM[dataset]):.2f}%\")\n",
        "    print(f\"Average Testing Time: --- {np.mean(testing_time_SVM[dataset]):.4f} seconds ---\")\n",
        "    print(f\"Average Testing Accuracy: --- {np.mean(testing_accuracy_SVM[dataset]):.2f}%\")\n",
        "    print(f\"Average Testing F1 Score: --- {np.mean(testing_f1_score_SVM[dataset]):.2f}%\\n\")\n",
        "    \"\"\"\n",
        "    # Plot metric values at end of train-test cycle\n",
        "    loss_fig = plt.figure(0)\n",
        "    plt.figure(0)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.title('Model Loss: Categorical Cross-entropy')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_fig = plt.figure(1)\n",
        "    plt.figure(1)\n",
        "    plt.plot(history.history['mse'])\n",
        "    plt.title('Regression Metrics')\n",
        "    plt.ylabel('Metric')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['MSE'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "    acc_fig = plt.figure(2)\n",
        "    plt.figure(2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.title('Model Accuracy: Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "    f1_fig = plt.figure(3)\n",
        "    plt.figure(3)\n",
        "    plt.plot(history.history['f1_score'])\n",
        "    plt.title('F1 Score')\n",
        "    plt.ylabel('f1 score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "    recall_fig = plt.figure(4)\n",
        "    plt.figure(4)\n",
        "    plt.plot(history.history['recall'])\n",
        "    plt.title('recall')\n",
        "    plt.ylabel('recall')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "    val_fig = plt.figure(5)\n",
        "    plt.figure(5)\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\"\"\"\n",
        "\n",
        "\n",
        "    print('Confusion matrix')\n",
        "    print(classifier_confusion_matrix)\n",
        "\n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in classifier_confusion_matrix.flatten()]\n",
        "\n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in classifier_confusion_matrix.flatten()/np.sum(classifier_confusion_matrix)]\n",
        "\n",
        "    labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in zip(group_counts,group_percentages)]\n",
        "\n",
        "    labels = np.asarray(labels).reshape(5,5)\n",
        "\n",
        "    ax = sns.heatmap(classifier_confusion_matrix, annot=True, fmt='', cmap='Blues')\n",
        "\n",
        "    ax.set_title('Confusion Matrix \\n\\n');\n",
        "    ax.set_xlabel('\\nPredicted Values')\n",
        "    ax.set_ylabel('Actual Values ');\n",
        "\n",
        "    ## Ticket labels - List must be in alphabetical order\n",
        "    ax.xaxis.set_ticklabels(['Normal','Less Normall','...','...','More Faulty'])\n",
        "    ax.yaxis.set_ticklabels(['Normal','Less Normall','...','...','More Faulty'])\n",
        "\n",
        "    ## Display the visualization of the Confusion Matrix.\n",
        "    plt.show()\n",
        "    \n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    threshold = {}\n",
        "    for i in range(5): \n",
        "        fpr[i], tpr[i], threshold[i]  = roc_curve(y_test, y_test_pred, pos_label=i)\n",
        "        \n",
        "    # plotting    \n",
        "    plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0')\n",
        "    plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1')\n",
        "    plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2')\n",
        "    plt.plot(fpr[3], tpr[3], linestyle='--',color='red', label='Class 3')\n",
        "    plt.plot(fpr[4], tpr[4], linestyle='--',color='yellow', label='Class 4')\n",
        "    plt.title('Auc ROC curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive rate')\n",
        "    plt.legend(loc='best')\n",
        "    plt.savefig('Auc ROC',dpi=300);  \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(\"----------------------------------------------\\n\")\n",
        "    print(f\"------------- {dataset[:-4]} Summary -------------\")\n",
        "    for i in range(iterations):\n",
        "        print(f\"Training Time_{i+1}: --- {training_time_SVM[dataset][i]:.4f} seconds ---\")\n",
        "        print(f\"Training Accuracy_{i+1}: --- {training_accuracy_SVM[dataset][i]:.2f}%\")\n",
        "        print(f\"Training F1 Score_{i+1}: --- {training_f1_score_SVM[dataset][i]:.2f}%\")\n",
        "        print(f\"Testing Time_{i+1}: --- {testing_time_SVM[dataset][i]:.4f} seconds ---\")\n",
        "        print(f\"Testing Accuracy_{i+1}: --- {testing_accuracy_SVM[dataset][i]:.2f}%\")\n",
        "        print(f\"Testing F1 Score_{i+1}: --- {testing_f1_score_SVM[dataset][i]:.2f}%\")\n",
        "        print(\"----------------------------------------------\\n\")\n",
        "\n",
        "    print(f\"\\nAverage Training Time: --- {np.mean(training_time_SVM[dataset]):.4f} seconds ---\")\n",
        "    print(f\"Average Training Accuracy: --- {np.mean(training_accuracy_SVM[dataset]):.2f}%\")\n",
        "    print(f\"Average Training F1 Score: --- {np.mean(training_f1_score_SVM[dataset]):.2f}%\")\n",
        "    print(f\"Average Testing Time: --- {np.mean(testing_time_SVM[dataset]):.4f} seconds ---\")\n",
        "    print(f\"Average Testing Accuracy: --- {np.mean(testing_accuracy_SVM[dataset]):.2f}%\")\n",
        "    print(f\"Average Testing F1 Score: --- {np.mean(testing_f1_score_SVM[dataset]):.2f}%\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "6cMOHNHDNm9I",
        "outputId": "7110ee0a-f1bf-4085-fb3b-faace0d2867d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------- DRED Execution -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size: (166353, 6)\n",
            "\n",
            "Accuracy: 0.9735505395088816\n",
            "mse: 0.3864927414264675\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4ec0f67f25da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mse:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinge_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mclassifier_confusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mhinge_loss\u001b[0;34m(y_true, pred_decision, labels, sample_weight)\u001b[0m\n\u001b[1;32m   2534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2536\u001b[0;31m                 \u001b[0;34m\"The shape of pred_decision cannot be 1d array\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2537\u001b[0m                 \u001b[0;34m\"with a multiclass target. pred_decision shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m                 \u001b[0;34m\"must be (n_samples, n_classes), that is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The shape of pred_decision cannot be 1d arraywith a multiclass target. pred_decision shape must be (n_samples, n_classes), that is (33271, 5). Got: (33271,)"
          ]
        }
      ]
    }
  ]
}